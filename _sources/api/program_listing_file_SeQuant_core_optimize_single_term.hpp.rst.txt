
.. _program_listing_file_SeQuant_core_optimize_single_term.hpp:

Program Listing for File single_term.hpp
========================================

|exhale_lsh| :ref:`Return to documentation for file <file_SeQuant_core_optimize_single_term.hpp>` (``SeQuant/core/optimize/single_term.hpp``)

.. |exhale_lsh| unicode:: U+021B0 .. UPWARDS ARROW WITH TIP LEFTWARDS

.. code-block:: cpp

   #ifndef SEQUANT_CORE_OPTIMIZE_SINGLE_TERM_HPP
   #define SEQUANT_CORE_OPTIMIZE_SINGLE_TERM_HPP
   
   #include <SeQuant/core/container.hpp>
   #include <SeQuant/core/expr.hpp>
   #include <SeQuant/core/tensor_network.hpp>
   #include <SeQuant/core/utility/indices.hpp>
   #include <SeQuant/core/utility/macros.hpp>
   
   #include <range/v3/view.hpp>
   
   #include <bit>
   #include <type_traits>
   
   namespace sequant::opt {
   template <typename F>
   concept has_index_extent = std::is_invocable_r_v<size_t, F, Index const&>;
   namespace detail {
   
   auto constexpr flops_counter(has_index_extent auto&& ixex) {
     return [ixex](meta::range_of<Index> auto const& lhs,
                   meta::range_of<Index> auto const& rhs,
                   meta::range_of<Index> auto const& result) {
       using ranges::views::concat;
       auto tot_idxs = tot_indices<container::set<Index, Index::LabelCompare>>(
           concat(lhs, rhs, result));
       double ops = 1.;
       for (auto&& idx : concat(tot_idxs.outer, tot_idxs.inner)) ops *= ixex(idx);
       // ops == 1 implies zero flops
       return ops == 1. ? 0. : ops;
     };
   }
   
   struct OptRes {
     container::svector<sequant::Index> indices;
   
     double flops;
   
     EvalSequence sequence;
   };
   
   template <typename CostFn>
     requires requires(CostFn&& fn, decltype(OptRes::indices) const& ixs) {
       { std::forward<CostFn>(fn)(ixs, ixs, ixs) } -> std::floating_point;
     }
   EvalSequence single_term_opt_impl(TensorNetwork const& network,
                                     meta::range_of<Index> auto const& tidxs,
                                     CostFn&& cost_fn) {
     using ranges::views::concat;
     using ranges::views::indirect;
     using ranges::views::transform;
     using IndexContainer = decltype(OptRes::indices);
     auto const nt = network.tensors().size();
     if (nt == 1) return EvalSequence{0};
     if (nt == 2) return EvalSequence{0, 1, -1};
   
     container::vector<OptRes> results((size_t{1} << nt));
   
     // initialize the intermediate results
     {
       auto tensor_indices = network.tensors()  //
                             | indirect         //
                             | transform(slots);
       auto imed_indices = subset_target_indices(tensor_indices, tidxs);
       SEQUANT_ASSERT(ranges::distance(imed_indices) == ranges::distance(results));
       for (size_t i = 0; i < results.size(); ++i) {
         results[i].indices =
             imed_indices[i] | ranges::views::move | ranges::to<IndexContainer>;
         results[i].flops =
             std::popcount(i) > 1
                 ? std::numeric_limits<decltype(OptRes::flops)>::max()
                 : 0;
         if (std::popcount(i) == 1)
           results[i].sequence.emplace_back(std::countr_zero(i));
         // else results[i].sequence is left uninitialized
       }
     }
   
     // find the optimal evaluation sequence
     for (size_t n = 0; n < results.size(); ++n) {
       if (std::popcount(n) < 2) continue;
       std::pair<size_t, size_t> curr_parts{0, 0};
       for (auto& curr_cost = results[n].flops;
            auto&& [lp, rp] : bits::bipartitions(n)) {
         // do nothing with the trivial bipartition
         // i.e. one subset is the empty set and the other full
         if (lp == 0 || rp == 0) continue;
         auto new_cost = std::forward<CostFn>(cost_fn)(results[lp].indices,  //
                                                       results[rp].indices,  //
                                                       results[n].indices)   //
                         + results[lp].flops + results[rp].flops;
         if (new_cost <= curr_cost) {
           curr_cost = new_cost;
           curr_parts = decltype(curr_parts){lp, rp};
         }
       }
       auto const& lseq = results[curr_parts.first].sequence;
       auto const& rseq = results[curr_parts.second].sequence;
       results[n].sequence =
           (lseq[0] < rseq[0] ? concat(lseq, rseq) : concat(rseq, lseq)) |
           ranges::to<EvalSequence>;
       results[n].sequence.push_back(-1);
     }
   
     return results.back().sequence;
   }
   
   template <has_index_extent IdxToSz>
   EvalSequence single_term_opt(TensorNetwork const& network, IdxToSz&& idxsz) {
     auto cost_fn = flops_counter(std::forward<IdxToSz>(idxsz));
     decltype(OptRes::indices) tidxs{};
     return single_term_opt_impl(network, tidxs, cost_fn);
   }
   
   }  // namespace detail
   
   template <has_index_extent IdxToSz>
   ExprPtr single_term_opt(Product const& prod, IdxToSz&& idxsz) {
     using ranges::views::filter;
     using ranges::views::reverse;
   
     if (prod.factors().size() < 3)
       return ex<Product>(Product{prod.scalar(), prod.factors().begin(),
                                  prod.factors().end(), Product::Flatten::No});
     auto const tensors =
         prod | filter(&ExprPtr::template is<Tensor>) | ranges::to_vector;
     auto seq = detail::single_term_opt(TensorNetwork{tensors},
                                        std::forward<IdxToSz>(idxsz));
     auto result = container::svector<ExprPtr>{};
     for (auto i : seq)
       if (i == -1) {
         auto rexpr = *result.rbegin();
         result.pop_back();
         auto lexpr = *result.rbegin();
         result.pop_back();
         auto p = Product{1, ExprPtrList{lexpr, rexpr}, Product::Flatten::No};
         result.push_back(ex<Product>(Product{
             1, p.factors().begin(), p.factors().end(), Product::Flatten::No}));
       } else {
         result.push_back(tensors.at(i));
       }
   
     auto& p_ = (*result.rbegin()).as<Product>();
     for (auto&& v : prod | reverse | filter(&Expr::template is<Variable>))
       p_.prepend(1, v, Product::Flatten::No);
   
     p_.scale(prod.scalar());
     return *result.rbegin();
   }
   
   }  // namespace sequant::opt
   
   #endif  // SEQUANT_CORE_OPTIMIZE_SINGLE_TERM_HPP
